"""Instruction generation utilities."""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

from langchain.chains import LLMChain
from langchain_core.language_models.chat_models import BaseChatModel
from langchain.prompts import PromptTemplate

from .tools import ToolRegistry

JSONDict = Dict[str, Any]


class InstructionGenerator:
    """Wraps an ``LLMChain`` to produce JSON Playwright instructions."""

    def __init__(self, llm: BaseChatModel) -> None:
        template = PromptTemplate(
            input_variables=["step", "html", "history", "feedback"],
            template=(
                "You generate JSON Playwright instructions.\n"
                "Follow this schema exactly: {\n"
                "  \"actions\": [\n"
                "    {\n"
                "      \"type\": one of [\"goto\", \"click\", \"fill\", \"expect\", \"assert_text\"],\n"
                "      \"selector\": CSS selector when applicable,\n"
                "      \"value\": text for \"fill\",\n"
                "      \"text\": assertion text for \"assert_text\",\n"
                "      \"url\": absolute or relative URL for \"goto\"\n"
                "    }\n"
                "  ],\n"
                "  \"comment\": short reasoning string\n"
                "}.\n"
                "Use information from the current HTML to pick selectors.\n"
                "Keep actions minimal yet sufficient.\n"
                "History of prior steps and actions:\n{history}\n\n"
                "Additional feedback, prior errors, or selector hints:\n{feedback}\n\n"
                "Current page HTML snippet:\n{html}\n\n"
                "Current manual step: {step}\n\n"
                "Return only valid JSON."
            ),
        )
        self._chain = LLMChain(llm=llm, prompt=template)

    async def agenerate(
        self,
        *,
        step: str,
        html: str,
        history: List[JSONDict],
        feedback: Optional[str] = None,
    ) -> JSONDict:
        """Generate a JSON instruction for the given step."""

        history_str = json.dumps(history, ensure_ascii=False, indent=2)
        feedback_value = feedback or "None"
        raw = await self._chain.apredict(
            step=step,
            html=html,
            history=history_str,
            feedback=feedback_value,
        )
        return self._clean_json(raw)

    @staticmethod
    def _clean_json(raw: str) -> JSONDict:
        snippet = raw.strip()
        start = snippet.find("{")
        end = snippet.rfind("}")
        if start == -1 or end == -1 or end < start:
            raise ValueError(f"Model response is not JSON: {raw}")
        snippet = snippet[start : end + 1]
        try:
            return json.loads(snippet)
        except json.JSONDecodeError as exc:  # pragma: no cover - validation
            raise ValueError(f"Invalid JSON from model: {raw}") from exc


@dataclass
class PlannedInstruction:
    """Instruction plus metadata about how it was produced."""

    instruction: JSONDict
    source: str
    metadata: Dict[str, Any] = field(default_factory=dict)


class ReactiveInstructionPlanner:
    """Chooses between specialised tools and the LLM for each step."""

    def __init__(self, generator: InstructionGenerator, tools: Optional[ToolRegistry] = None) -> None:
        self._generator = generator
        self._tools = tools or ToolRegistry()

    async def agenerate(
        self,
        *,
        step: str,
        html: str,
        history: List[JSONDict],
        feedback: Optional[str] = None,
        use_tools: bool = True,
    ) -> PlannedInstruction:
        """Generate instructions, preferring specialised tools when available."""

        if use_tools:
            tool_result = await self._tools.arun(
                step=step,
                html=html,
                history=history,
                feedback=feedback,
            )
            if tool_result:
                instruction = tool_result.instruction
                instruction.setdefault(
                    "comment",
                    f"Generated with tool {tool_result.tool_name}",
                )
                return PlannedInstruction(
                    instruction=instruction,
                    source=f"tool:{tool_result.tool_name}",
                    metadata=tool_result.metadata,
                )

        instruction = await self._generator.agenerate(
            step=step,
            html=html,
            history=history,
            feedback=feedback,
        )
        instruction.setdefault("comment", "Generated by LLM")
        return PlannedInstruction(instruction=instruction, source="llm")
